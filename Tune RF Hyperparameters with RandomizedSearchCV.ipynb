{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [required]\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#preprocess data\n",
    "data = pd.read_csv(\"used_car_train_20200313_revised.csv\", index_col='SaleID')\n",
    "\n",
    "y = data['price']\n",
    "X = data.drop('price',axis=1) #dropped about 15000 rows with missing values\n",
    "\n",
    "def preprocess(X_train):# handling missing values: transform 'notRepairedDamage column from 0, -, 1 to 0,1,2\n",
    "    new_col = X_train.notRepairedDamage.map(lambda x: 1 if x == '-' else int(float(x))*2)\n",
    "    X_train = X_train.drop('notRepairedDamage',axis=1)\n",
    "    X_train = X_train.join(new_col)   \n",
    "    return X_train\n",
    "\n",
    "def validate(model, X_train, X_valid, y_train, y_valid):\n",
    "    preds_valid = model.predict(X_valid)\n",
    "    preds_train = model.predict(X_train)\n",
    "    mae_valid = mean_absolute_error(preds_valid, y_valid)\n",
    "    mae_train = mean_absolute_error(preds_train, y_train)\n",
    "    print(\"Validation result:\")\n",
    "    print(\"train set mae on training set is {}\".format(mae_train))\n",
    "    print(\"valid set mae on validation set is {}\".format(mae_valid))\n",
    "\n",
    "selected_cols=['v_12','v_10','regDate','kilometer','v_0','v_14','power','v_8','v_1','v_5','v_3','v_11',\n",
    "                   'v_9','v_6','v_4','notRepairedDamage','model','v_2','v_13','name','brand','v_7','fuelType']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [validation only]\n",
    "imputer = SimpleImputer()\n",
    "(X_train, X_valid, y_train, y_valid) = train_test_split(X, y, test_size=0.1)\n",
    "X_train = preprocess(X_train)\n",
    "X_valid = preprocess(X_valid)\n",
    "cols = X_train.columns\n",
    "\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "X_valid = pd.DataFrame(imputer.transform(X_valid))\n",
    "X_train.columns = cols\n",
    "X_valid.columns = cols\n",
    "\n",
    "X_train = X_train[selected_cols]\n",
    "X_valid = X_valid[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [model-build only]\n",
    "full_X = preprocess(X)\n",
    "final_imputer = SimpleImputer()\n",
    "full_X = pd.DataFrame(final_imputer.fit_transform(full_X))\n",
    "full_X.columns = cols\n",
    "full_X = full_X[selected_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'max_leaf_nodes': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, None],\n",
      " 'min_impurity_decrease': [0.0,\n",
      "                           0.05,\n",
      "                           0.1,\n",
      "                           0.15,\n",
      "                           0.2,\n",
      "                           0.25,\n",
      "                           0.3,\n",
      "                           0.35,\n",
      "                           0.4,\n",
      "                           0.45,\n",
      "                           0.5],\n",
      " 'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
      " 'warm_start': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "# [validation only]\n",
    "# Tune HyperParameters\n",
    "n_estimators = [int(x) for x in np.linspace(start=10, stop=100, num=10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10,110,num=11)]\n",
    "max_depth.append(None)\n",
    "bootstrap = [True, False]\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(start=100,stop=1000,num=10)]\n",
    "max_leaf_nodes.append(None)\n",
    "min_impurity_decrease = [float(x/100) for x in np.linspace(start=0, stop=50, num=11)]\n",
    "warm_start=[True, False]\n",
    "\n",
    "random_grid = {'n_estimators':n_estimators,\n",
    "              'max_features':max_features,\n",
    "              'max_depth':max_depth,\n",
    "              'bootstrap':bootstrap,\n",
    "              'max_leaf_nodes':max_leaf_nodes,\n",
    "              'min_impurity_decrease':min_impurity_decrease,\n",
    "              'warm_start':warm_start}\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 86.1min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 169.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   ccp_alpha=0.0,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   max_samples=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=100,\n",
       "                                                   n_jobs=None, oob_score=Fals...\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'max_leaf_nodes': [100, 200, 300, 400,\n",
       "                                                           500, 600, 700, 800,\n",
       "                                                           900, 1000, None],\n",
       "                                        'min_impurity_decrease': [0.0, 0.05,\n",
       "                                                                  0.1, 0.15,\n",
       "                                                                  0.2, 0.25,\n",
       "                                                                  0.3, 0.35,\n",
       "                                                                  0.4, 0.45,\n",
       "                                                                  0.5],\n",
       "                                        'n_estimators': [10, 20, 30, 40, 50, 60,\n",
       "                                                         70, 80, 90, 100],\n",
       "                                        'warm_start': [True, False]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [validation only]\n",
    "# Fit and validate model to get the best model settings (hyperparameters)\n",
    "rf = RandomForestRegressor()\n",
    "rf_random = RandomizedSearchCV(estimator=rf,param_distributions=random_grid, n_iter=100, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'warm_start': False,\n",
       " 'n_estimators': 50,\n",
       " 'min_impurity_decrease': 0.05,\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 30,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (you can ignore this part)\n",
    "# get the best estimator's hyperparameters set\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [model-build only]\n",
    "final_params = {'warm_start': False,\n",
    "                'n_estimators': 50,\n",
    "                'min_impurity_decrease': 0.05,\n",
    "                'max_leaf_nodes': None,\n",
    "                'max_features': 'sqrt',\n",
    "                'max_depth': 30,\n",
    "                'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "50\n",
      "0.05\n",
      "None\n",
      "sqrt\n",
      "30\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# (you can ignore this part)\n",
    "def sample(warm_start=None, n_estimators=10, min_impurity_decrease=0, \n",
    "           max_leaf_nodes=None, max_features='sqrt',max_depth=30,bootstrap=False):\n",
    "    print(warm_start)\n",
    "    print(n_estimators)\n",
    "    print(min_impurity_decrease)\n",
    "    print(max_leaf_nodes)\n",
    "    print(max_features)\n",
    "    print(max_depth)\n",
    "    print(bootstrap)\n",
    "\n",
    "sample(**final_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation result:\n",
      "train set mae on sample training set is 68.66492637759661\n",
      "valid set mae on full validation set is 65.23382025009309\n"
     ]
    }
   ],
   "source": [
    "# [validation only]\n",
    "# validate: (train score & valid score)\n",
    "# rf_random.best_estimator_ is the estimator with best params, validation purpose only\n",
    "# should do a model-build with best parameters on full dataset\n",
    "\n",
    "validate(rf_random.best_estimator_, X_train, X_valid, y_train, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_full_grid_FE_model.joblib']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [model-build only]\n",
    "# model build\n",
    "final_rf_model = RandomForestRegressor(final_params)\n",
    "final_rf_model.fit(full_X, y)\n",
    "\n",
    "# save model as file\n",
    "from joblib import dump\n",
    "dump(final_rf_model, \"FINALBUILT_rf_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (You can ignore this part) This is a draft note on grid search results\n",
    "1500:\n",
    "{'warm_start': True,\n",
    " 'n_estimators': 80,\n",
    " 'min_impurity_decrease': 0.0,\n",
    " 'max_leaf_nodes': 500,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': True}\n",
    "\n",
    "4000\n",
    "{'warm_start': True,\n",
    " 'n_estimators': 90,\n",
    " 'min_impurity_decrease': 0.3,\n",
    " 'max_leaf_nodes': 900,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 80,\n",
    " 'bootstrap': False}\n",
    "\n",
    "10000\n",
    "{'warm_start': True,\n",
    " 'n_estimators': 50,\n",
    " 'min_impurity_decrease': 0.1,\n",
    " 'max_leaf_nodes': 700,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 110,\n",
    " 'bootstrap': False}\n",
    "\n",
    "full_X(train+valid)\n",
    "{'warm_start': False,\n",
    " 'n_estimators': 50,\n",
    " 'min_impurity_decrease': 0.05,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 30,\n",
    " 'bootstrap': False}\n",
    "\n",
    "X_Train\n",
    "{'warm_start': False,\n",
    " 'n_estimators': 50,\n",
    " 'min_impurity_decrease': 0.05,\n",
    " 'max_leaf_nodes': None,\n",
    " 'max_features': 'sqrt',\n",
    " 'max_depth': 30,\n",
    " 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Output] Output result\n",
    "X_test = pd.read_csv(\"used_car_testA_20200313_revised.csv\", index_col='SaleID')\n",
    "X_test = preprocess(X_test)\n",
    "X_test = pd.DataFrame(final_imputer.transform(X_test))\n",
    "X_test.columns = cols\n",
    "X_test = X_test[selected_cols]\n",
    "preds = final_rf_model.predict(X_test)\n",
    "result = pd.DataFrame({\"SaleID\":X_test.index, \"price\":preds})\n",
    "result.to_csv(\"FINAL_rf_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
